{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/briomianopc/opc/blob/main/cagliostro-forge-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![visitor][visitor-badge]][visitor-stats]\n",
        "\n",
        "# **Cagliostro Forge Colab**\n",
        "Rise from the ashes, reborn and empowered by [lllyasviel/stable-diffusion-webui-forge](https://github.com/lllyasviel/stable-diffusion-webui-forge)\n",
        "\n",
        "**Version 1.0.0** | [Github][link-to-github] | [License](https://github.com/cagliostrolab/forge-colab/blob/main/LICENSE)\n",
        "\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=cagliostro-forge-colab&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=cagliostro-forge-colab\n",
        "[link-to-github]: https://github.com/cagliostrolab/forge-colab/blob/main/cagliostro-forge-colab.ipynb"
      ],
      "metadata": {
        "id": "GnmYPpV3o719"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Install Environment**\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import string\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from pydantic import BaseModel\n",
        "\n",
        "python_version  = \".\".join(sys.version.split(\".\")[:2])\n",
        "python_path     = Path(f\"/usr/local/lib/python{python_version}/dist-packages/\")\n",
        "colablib_path   = python_path / \"colablib\"\n",
        "if not colablib_path.exists():\n",
        "    subprocess.run(['pip', 'install', '--upgrade', 'git+https://github.com/Linaqruf/colablib'], check=True)\n",
        "\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from colablib.utils import py_utils, package_utils, config_utils\n",
        "from colablib.sd_models.downloader import aria2_download, download\n",
        "from colablib.utils.git_utils import update_repo, reset_repo, validate_repo, batch_update\n",
        "from colablib.utils.py_utils import get_filename\n",
        "\n",
        "################################\n",
        "# COLAB ARGUMENTS GOES HERE\n",
        "################################\n",
        "\n",
        "# It ain't much, but it's honest work.\n",
        "class CustomDirs(BaseModel):\n",
        "    url: str\n",
        "    dst: str\n",
        "\n",
        "# @markdown ### **Drive Config**\n",
        "mount_drive          = False  # @param {type: 'boolean'}\n",
        "output_drive_folder  = \"cagliostro-colab-forge\"  # @param {type: 'string'}\n",
        "\n",
        "# @markdown ### **Repo Config**\n",
        "update_webui         = True  # @param {type: 'boolean'}\n",
        "update_extensions    = True  # @param {type: 'boolean'}\n",
        "commit_hash          = \"\"  # @param {type: 'string'}\n",
        "\n",
        "# @markdown ### **Download Config**\n",
        "# @markdown > Check only the options you need\n",
        "animagine_xl_3_1     = True  # @param {type: 'boolean'}\n",
        "rae_diffusion_xl_v2  = False  # @param {type: 'boolean'}\n",
        "kivotos_xl_v2_0      = False  # @param {type: 'boolean'}\n",
        "urangdiffusion_2_0   = False  # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown > **Note:**\n",
        "# @markdown - For multiple URLs, use comma separation (e.g. `url1, url2, url3`)\n",
        "# @markdown - Forge supports FLUX, SD, and SDXL, but this notebook focuses only on SDXL\n",
        "# @markdown - **Highly Recommended:** Use Hugging Face links whenever possible\n",
        "custom_model_url     = \"https://civitai.com/api/download/models/2167369?type=Model&format=SafeTensor&size=pruned&fp=fp16\"  # @param {'type': 'string'}\n",
        "custom_vae_url       = \"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl.vae.safetensors\"  # @param {'type': 'string'}\n",
        "custom_lora_url      = \"\"  # @param {'type': 'string'}\n",
        "\n",
        "# @markdown ### **Tunnel Config**\n",
        "# @markdown > Default to `--share` until `ngrok_token` is not `None`\n",
        "ngrok_token          = \"\"  # @param {type: 'string'}\n",
        "ngrok_region         = \"ap\"  # @param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "\n",
        "# @markdown ### **UI/UX Config**\n",
        "gradio_theme         = \"remilia/Ghostly\"  # @param [\"Default\", \"gradio/base\", \"gradio/glass\", \"gradio/monochrome\", \"gradio/seafoam\", \"gradio/soft\", \"gradio/dracula_test\", \"abidlabs/dracula_test\", \"abidlabs/Lime\", \"abidlabs/pakistan\", \"Ama434/neutral-barlow\", \"dawood/microsoft_windows\", \"finlaymacklon/smooth_slate\", \"Franklisi/darkmode\", \"freddyaboulton/dracula_revamped\", \"freddyaboulton/test-blue\", \"gstaff/xkcd\", \"Insuz/Mocha\", \"Insuz/SimpleIndigo\", \"JohnSmith9982/small_and_pretty\", \"nota-ai/theme\", \"nuttea/Softblue\", \"ParityError/Anime\", \"reilnuud/polite\", \"remilia/Ghostly\", \"rottenlittlecreature/Moon_Goblin\", \"step-3-profit/Midnight-Deep\", \"Taithrah/Minimal\", \"ysharma/huggingface\", \"ysharma/steampunk\", \"NoCrypt/miku\"]\n",
        "# @markdown Set `use_preset` for using default prompt, resolution, sampler, and other settings\n",
        "use_presets          = True  # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown ### **Launch Arguments**\n",
        "use_gradio_auth      = False  # @param {type: 'boolean'}\n",
        "auto_select_model    = False  # @param {type: 'boolean'}\n",
        "auto_select_vae      = True  # @param {type: 'boolean'}\n",
        "additional_arguments = \"--lowram --theme dark --no-half-vae --opt-sdp-attention\"  # @param {type: 'string'}\n",
        "\n",
        "################################\n",
        "# GLOBAL VARIABLES GOES HERE\n",
        "################################\n",
        "\n",
        "# GRADIO AUTH\n",
        "user      = \"cagliostro\"\n",
        "password  = \"\".join(random.choices(string.ascii_letters + string.digits, k=6))\n",
        "\n",
        "# ROOT DIR\n",
        "root_dir        = Path(\"/content\")\n",
        "drive_dir       = root_dir / \"drive\" / \"MyDrive\"\n",
        "repo_dir        = root_dir / \"stable-diffusion-webui-forge\"\n",
        "tmp_dir         = root_dir / \"tmp\"\n",
        "\n",
        "models_dir      = repo_dir / \"models\"\n",
        "extensions_dir  = repo_dir / \"extensions\"\n",
        "ckpt_dir        = models_dir / \"Stable-diffusion\"\n",
        "vae_dir         = models_dir / \"VAE\"\n",
        "lora_dir        = models_dir / \"Lora\"\n",
        "output_subdir   = [\"txt2img-samples\", \"img2img-samples\", \"extras-samples\", \"txt2img-grids\", \"img2img-grids\"]\n",
        "\n",
        "config_file_path    = repo_dir / \"config.json\"\n",
        "ui_config_file_path = repo_dir / \"ui-config.json\"\n",
        "\n",
        "package_url = [\n",
        "    \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui-forge.tar.lz4\",\n",
        "    \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui-forge-deps.tar.lz4\",\n",
        "]\n",
        "\n",
        "custom_dirs = {\n",
        "    \"model\" : CustomDirs(url=custom_model_url, dst=str(ckpt_dir)),\n",
        "    \"vae\"   : CustomDirs(url=custom_vae_url, dst=str(vae_dir)),\n",
        "    \"lora\"  : CustomDirs(url=custom_lora_url, dst=str(lora_dir)),\n",
        "}\n",
        "\n",
        "default_model_urls = {\n",
        "    \"animagine_xl_3_1\"      : \"https://huggingface.co/cagliostrolab/animagine-xl-3.1/resolve/main/animagine-xl-3.1.safetensors\",\n",
        "    \"rae_diffusion_xl_v2\"   : \"https://huggingface.co/Raelina/Rae-Diffusion-XL-V2/resolve/main/RaeDiffusion-XL-v2.safetensors\",\n",
        "    \"kivotos_xl_v2_0\"       : \"https://huggingface.co/yodayo-ai/kivotos-xl-2.0/resolve/main/kivotos-xl-2.0.safetensors\",\n",
        "    \"urangdiffusion_2_0\"    : \"https://huggingface.co/kayfahaarukku/UrangDiffusion-2.0/resolve/main/UrangDiffusion-2.0.safetensors\",\n",
        "}\n",
        "\n",
        "################################\n",
        "# HELPER FUNCTIONS STARTS HERE\n",
        "################################\n",
        "\n",
        "def mount_drive_function(directory):\n",
        "    output_dir = repo_dir / \"outputs\"\n",
        "\n",
        "    if mount_drive:\n",
        "        print_line(80, color=\"green\")\n",
        "        if not directory.exists():\n",
        "            from google.colab import drive\n",
        "            cprint(\"Mounting google drive...\", color=\"green\", reset=False)\n",
        "            drive.mount(str(directory.parent))\n",
        "        output_dir = directory / output_drive_folder\n",
        "        cprint(\"Set default output path to:\", output_dir, color=\"green\")\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "def setup_directories():\n",
        "    for dir in [ckpt_dir, vae_dir, lora_dir]:\n",
        "        dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def pre_download(dir, urls, desc, overwrite=False):\n",
        "    ffmpy_path = python_path / \"ffmpy-0.3.0.dist-info\"\n",
        "\n",
        "    for url in tqdm(urls, desc=desc):\n",
        "        filename = Path(url).name\n",
        "        aria2_download(dir, filename, url, quiet=True)\n",
        "        if filename == \"webui-forge-deps.tar.lz4\":\n",
        "            package_utils.extract_package(filename, python_path, overwrite=True)\n",
        "        else:\n",
        "            package_utils.extract_package(filename, \"/\", overwrite=overwrite)\n",
        "        os.remove(dir / filename)\n",
        "\n",
        "    subprocess.run([\"rm\", \"-rf\", str(ffmpy_path)])\n",
        "    subprocess.run([\"pip\", \"install\", \"--force-reinstall\", \"ffmpy\"], check=True)\n",
        "\n",
        "def install_dependencies():\n",
        "    ubuntu_deps = [\"aria2\", \"lz4\"]\n",
        "    cprint(\"Installing ubuntu dependencies\", color=\"green\")\n",
        "    subprocess.run([\"apt\", \"install\", \"-y\"] + ubuntu_deps, check=True)\n",
        "\n",
        "def install_webui(repo_dir, desc):\n",
        "    if not repo_dir.exists():\n",
        "        pre_download(root_dir, package_url, desc, overwrite=False)\n",
        "    else:\n",
        "        cprint(\"Stable Diffusion Web UI Forge already installed, skipping...\", color=\"green\")\n",
        "\n",
        "def configure_output_path(config_path, output_dir, output_subdir):\n",
        "    try:\n",
        "        config = config_utils.read_config(str(config_path))\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        config = {}\n",
        "\n",
        "    config_updates = {\n",
        "        f\"outdir_{subdir.split('-')[0]}_{'_'.join(subdir.split('-')[1:])}\": str(output_dir / subdir)\n",
        "        for subdir in output_subdir\n",
        "    }\n",
        "    config.update(config_updates)\n",
        "\n",
        "    config_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    config_utils.write_config(str(config_path), config)\n",
        "\n",
        "    for dir in output_subdir:\n",
        "        (output_dir / dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def prepare_environment():\n",
        "    cprint(\"Preparing environment...\", color=\"green\")\n",
        "    os.environ['PYTORCH_CUDA_ALLOC_CONF']   = \"garbage_collection_threshold:0.9,max_split_size_mb:512\"\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]      = \"3\"\n",
        "    os.environ[\"PYTHONWARNINGS\"]            = \"ignore\"\n",
        "\n",
        "def custom_download(custom_dirs):\n",
        "    filtered_urls = filter_dict_items(default_model_urls)\n",
        "\n",
        "    for key, value in custom_dirs.items():\n",
        "        urls = value.url.split(\",\")\n",
        "        dst = value.dst\n",
        "\n",
        "        if key == \"model\":\n",
        "            urls.extend(filtered_urls)\n",
        "\n",
        "        if urls[0]:\n",
        "            print_line(80, color=\"green\")\n",
        "            cprint(f\" [-] Downloading Custom {key}...\", color=\"flat_yellow\")\n",
        "\n",
        "        for url in urls:\n",
        "            url = url.strip()\n",
        "            if url != \"\":\n",
        "                print_line(80, color=\"green\")\n",
        "                if \"|\" in url:\n",
        "                    url, filename = map(str.strip, url.split(\"|\"))\n",
        "                    if not filename.endswith((\".safetensors\", \".ckpt\", \".pt\", \"pth\")):\n",
        "                        filename = filename + Path(get_filename(url)).suffix\n",
        "                else:\n",
        "                    filename = get_filename(url)\n",
        "\n",
        "                download(url=url, filename=filename, dst=dst, quiet=False)\n",
        "\n",
        "def filter_dict_items(dict_items):\n",
        "    result_list = []\n",
        "    for key, url in dict_items.items():\n",
        "        if globals().get(key):\n",
        "            result_list.append(url)\n",
        "    return result_list\n",
        "\n",
        "def auto_select_file(target_dir, config_key, file_types):\n",
        "    valid_files = [f for f in os.listdir(target_dir) if f.endswith(file_types)]\n",
        "    if valid_files:\n",
        "        file_path = random.choice(valid_files)\n",
        "\n",
        "        if Path(target_dir).joinpath(file_path).exists():\n",
        "            config = config_utils.read_config(str(config_file_path))\n",
        "            config[config_key] = file_path\n",
        "            config_utils.write_config(str(config_file_path), config)\n",
        "        return file_path\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def ui_config_presets():\n",
        "    preset_prompt = \"masterpiece, best quality, very aesthetic, absurdres\"\n",
        "    preset_negative_prompt = \"nsfw, lowres, (bad), text, error, fewer, extra, missing, worst quality, jpeg artifacts, low quality, watermark, unfinished, displeasing, oldest, early, chromatic aberration, signature, extra digits, artistic error, username, scan, [abstract]\"\n",
        "\n",
        "    return {\n",
        "        \"txt2img/Prompt/value\"              : preset_prompt,\n",
        "        \"txt2img/Negative prompt/value\"     : preset_negative_prompt,\n",
        "        \"img2img/Prompt/value\"              : preset_prompt,\n",
        "        \"img2img/Negative prompt/value\"     : preset_negative_prompt,\n",
        "        \"customscript/sampler.py/txt2img/Sampling method/value\" : \"Euler a\",\n",
        "        \"customscript/sampler.py/txt2img/Sampling steps/value\"  : 28,\n",
        "        \"customscript/sampler.py/txt2img/Scheduler/value\"       : \"Automatic\",\n",
        "    }\n",
        "\n",
        "def ui_config_settings(ui_config_file: str):\n",
        "    config = config_utils.read_config(str(ui_config_file))\n",
        "    preset_config = ui_config_presets()\n",
        "\n",
        "    for key, value in preset_config.items():\n",
        "        config[key] = value\n",
        "\n",
        "    config_utils.write_config(str(ui_config_file), config)\n",
        "\n",
        "def general_config_presets(config_file: str, lora_dir: str, use_presets: bool, ui_config_file: str):\n",
        "    config = config_utils.read_config(str(config_file))\n",
        "\n",
        "    config.update({\n",
        "        \"CLIP_stop_at_last_layers\"      : 2,\n",
        "        \"show_progress_every_n_steps\"   : 10,\n",
        "        \"show_progressbar\"              : True,\n",
        "        \"samples_filename_pattern\"      : \"[model_name]_[seed]\",\n",
        "        \"show_progress_type\"            : \"Approx NN\",\n",
        "        \"live_preview_content\"          : \"Prompt\",\n",
        "        \"forge_preset\"                  : \"xl\",\n",
        "        \"xl_t2i_width\"                  : 832,\n",
        "        \"xl_t2i_height\"                 : 1216,\n",
        "        \"xl_t2i_cfg\"                    : 7,\n",
        "        \"xl_t2i_hr_cfg\"                 : 7,\n",
        "        \"xl_t2i_sampler\"                : \"Euler a\",\n",
        "        \"xl_t2i_scheduler\"              : \"Automatic\",\n",
        "        \"gradio_theme\"                  : gradio_theme,\n",
        "    })\n",
        "\n",
        "    config_utils.write_config(str(config_file), config)\n",
        "\n",
        "    if use_presets:\n",
        "        ui_config_settings(ui_config_file)\n",
        "\n",
        "def is_valid(target_dir, file_types):\n",
        "    return any(f.endswith(file_types) for f in os.listdir(target_dir))\n",
        "\n",
        "def parse_args(config):\n",
        "    args = []\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args.append(f'\"{v}\"')\n",
        "        elif isinstance(v, str):\n",
        "            args.append(f'--{k}=\"{v}\"')\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args.append(f\"--{k}\")\n",
        "        elif isinstance(v, (float, int)) and not isinstance(v, bool):\n",
        "            args.append(f\"--{k}={v}\")\n",
        "    return \" \".join(args)\n",
        "\n",
        "def main():\n",
        "    global output_dir, auto_select_model, auto_select_vae\n",
        "\n",
        "    ################################\n",
        "    # MAIN EXECUTION\n",
        "    ################################\n",
        "\n",
        "    os.chdir(root_dir)\n",
        "    start_time = time.time()\n",
        "    output_dir = mount_drive_function(drive_dir)\n",
        "\n",
        "    gpu_info    = py_utils.get_gpu_info(get_gpu_name=True)\n",
        "    python_info = py_utils.get_python_version()\n",
        "    torch_info  = py_utils.get_torch_version()\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\" [-] Current GPU: {gpu_info}\", color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Python {python_info}\", color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Torch {torch_info}\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    try:\n",
        "        install_dependencies()\n",
        "\n",
        "        print_line(80, color=\"green\")\n",
        "        install_webui(repo_dir, cprint(\"Unpacking Web UI Forge\", color=\"green\", tqdm_desc=True))\n",
        "        prepare_environment()\n",
        "\n",
        "        configure_output_path(config_file_path, output_dir, output_subdir)\n",
        "\n",
        "        print_line(80, color=\"green\")\n",
        "        if update_webui and not commit_hash:\n",
        "            update_repo(cwd=repo_dir, args=\"-X theirs --rebase --autostash\")\n",
        "        elif commit_hash:\n",
        "            reset_repo(repo_dir, commit_hash)\n",
        "\n",
        "        setup_directories()\n",
        "\n",
        "        repo_name, current_commit_hash, current_branch = validate_repo(repo_dir)\n",
        "        cprint(f\"Using '{repo_name}' repository...\", color=\"green\")\n",
        "        cprint(f\"Branch: {current_branch}, Commit hash: {current_commit_hash}\", color=\"green\")\n",
        "\n",
        "        if update_extensions:\n",
        "            print_line(80, color=\"green\")\n",
        "            batch_update(fetch=True, directory=extensions_dir, desc=cprint(\"Updating extensions\", color=\"green\", tqdm_desc=True))\n",
        "\n",
        "        elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "        print_line(80, color=\"green\")\n",
        "        cprint(f\"Finished installation. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    except Exception as e:\n",
        "        cprint(f\"An error occurred: {str(e)}\", color=\"red\")\n",
        "        print_line(80, color=\"red\")\n",
        "        cprint(\"Setup failed. Please check the error message above and try again.\", color=\"red\")\n",
        "        print_line(80, color=\"red\")\n",
        "        return\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    custom_download(custom_dirs)\n",
        "\n",
        "    elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Download finished. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Launching '{repo_name}'\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    if not is_valid(ckpt_dir, ('.ckpt', '.safetensors')):\n",
        "        cprint(f\"No checkpoints were found in the directory '{ckpt_dir}'.\", color=\"yellow\")\n",
        "        url = \"https://huggingface.co/cagliostrolab/animagine-xl-3.1/blob/main/animagine-xl-3.1.safetensors\"\n",
        "        filename = get_filename(url)\n",
        "        aria2_download(url=url, download_dir=ckpt_dir, filename=filename)\n",
        "        print_line(80, color=\"green\")\n",
        "        auto_select_model = True\n",
        "\n",
        "    if not is_valid(vae_dir, ('.vae.pt', '.vae.safetensors', '.pt', '.ckpt')):\n",
        "        cprint(f\"No VAEs were found in the directory '{vae_dir}'.\", color=\"yellow\")\n",
        "        url = \"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/blob/main/sdxl.vae.safetensors\"\n",
        "        filename = get_filename(url)\n",
        "        aria2_download(url=url, download_dir=vae_dir, filename=filename)\n",
        "        print_line(80, color=\"green\")\n",
        "        auto_select_vae = True\n",
        "\n",
        "    if auto_select_model:\n",
        "        selected_model  = auto_select_file(ckpt_dir, \"sd_model_checkpoint\", ('.ckpt', '.safetensors'))\n",
        "        cprint(f\"Selected Model: {selected_model}\", color=\"green\")\n",
        "\n",
        "    if auto_select_vae:\n",
        "        selected_vae    = auto_select_file(vae_dir, \"sd_vae\", ('.vae.pt', '.vae.safetensors', '.pt', '.ckpt'))\n",
        "        cprint(f\"Selected VAE: {selected_vae}\", color=\"green\")\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    general_config_presets(config_file_path, lora_dir, use_presets, ui_config_file_path)\n",
        "\n",
        "    if use_gradio_auth:\n",
        "      cprint(\"Gradio Auth (use this account to login):\", color=\"green\")\n",
        "      cprint(\"[-] Username: cagliostro\", color=\"green\")\n",
        "      cprint(\"[-] Password:\", password, color=\"green\")\n",
        "      print_line(80, color=\"green\")\n",
        "\n",
        "    config = {\n",
        "        \"enable-insecure-extension-access\": True,\n",
        "        \"disable-safe-unpickle\"           : True,\n",
        "        \"share\"                           : True if not ngrok_token else False,\n",
        "        \"ngrok\"                           : ngrok_token if ngrok_token else None,\n",
        "        \"ngrok-region\"                    : ngrok_region if ngrok_token else None,\n",
        "        \"gradio-auth\"                     : f\"{user}:{password}\" if use_gradio_auth else None,\n",
        "        \"no-hashing\"                      : True,\n",
        "        \"disable-console-progressbars\"    : True,\n",
        "        \"lowram\"                          : True,\n",
        "        \"opt-sub-quad-attention\"          : True,\n",
        "        \"opt-channelslast\"                : True,\n",
        "        \"no-download-sd-model\"            : True,\n",
        "        \"gradio-queue\"                    : True,\n",
        "        \"listen\"                          : True,\n",
        "        \"ckpt-dir\"                        : ckpt_dir,\n",
        "        \"vae-dir\"                         : vae_dir,\n",
        "        \"lora-dir\"                        : lora_dir,\n",
        "    }\n",
        "\n",
        "    args = parse_args(config)\n",
        "    final_args = f\"python launch.py {args} {additional_arguments}\"\n",
        "\n",
        "    cprint()\n",
        "    os.chdir(repo_dir)\n",
        "    ! {final_args}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "YYzHDlgEkkrY",
        "cellView": "form",
        "outputId": "305af37a-c9da-491e-d1b0-1b4082279588",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Current GPU: NVIDIA A100-SXM4-40GB\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Python 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Torch 2.6.0+cu124\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mInstalling ubuntu dependencies\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStable Diffusion Web UI Forge already installed, skipping...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mPreparing environment...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;31mError while pulling the repository in /content/stable-diffusion-webui-forge: error: Pulling is not possible because you have unmerged files.\n",
            "hint: Fix them up in the work tree, and then use 'git add/rm <file>'\n",
            "hint: as appropriate to mark resolution and make a commit.\n",
            "fatal: Exiting because of an unresolved conflict.\n",
            "\u001b[0m\n",
            "\u001b[0m\u001b[0;32mUsing 'lllyasviel/stable-diffusion-webui-forge' repository...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mBranch: main, Commit hash: dfdcbab685e57677014f05a3309b48cc87383167\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[0;32mUpdating extensions: 100%|██████████| 6/6 [00:01<00:00,  4.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0mFinished installation. Took 3 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Downloading Custom model...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'waiANINSFWPONYXL_v140.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'waiANINSFWPONYXL_v140.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'hassakuXLIllustrious_v30.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'hassakuXLIllustrious_v30.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'waiNSFWIllustrious_v140.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'waiNSFWIllustrious_v140.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'waiREALCN_v150.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'waiREALCN_v150.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'animagine-xl-3.1.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'animagine-xl-3.1.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Downloading Custom vae...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'sdxl.vae.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'sdxl.vae.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Downloading Custom lora...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'NSFWFilterXL_animagine.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'NSFWFilterXL_animagine.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'BDSM_0.2.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'BDSM_0.2.safetensors' completed. Took 1 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'Different_sex_positions_feets_on_screen-000009.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'Different_sex_positions_feets_on_screen-000009.safetensors' completed. Took 1 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'add-detail-xl.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'add-detail-xl.safetensors' completed. Took 1 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0mDownload finished. Took 6 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0mLaunching 'lllyasviel/stable-diffusion-webui-forge'\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mSelected VAE: sdxl.vae.safetensors\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0m\u001b[0m\n",
            "Python 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Version: f2.0.1v1.10.1-previous-669-gdfdcbab6\n",
            "Commit hash: dfdcbab685e57677014f05a3309b48cc87383167\n",
            "Legacy Preprocessor init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.\n",
            "Launching Web UI with arguments: --enable-insecure-extension-access --disable-safe-unpickle --share --no-hashing --disable-console-progressbars --lowram --opt-sub-quad-attention --opt-channelslast --no-download-sd-model --gradio-queue --listen --lowram --theme dark --no-half-vae --opt-sdp-attention\n",
            "Total VRAM 40507 MB, total RAM 85479 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 NVIDIA A100-SXM4-40GB : native\n",
            "VAE dtype preferences: [torch.bfloat16, torch.float32] -> torch.bfloat16\n",
            "CUDA Using Stream: False\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754494191.008032   16581 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754494191.014540   16581 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Using pytorch cross attention\n",
            "Using pytorch attention for VAE\n",
            "ControlNet preprocessor location: /content/stable-diffusion-webui-forge/models/ControlNetPreprocessor\n",
            "Tag Autocomplete: Could not locate model-keyword extension, Lora trigger word completion will be limited to those added through the extra networks menu.\n",
            "\u001b[38;5;208m▶\u001b[0m SD-Hub: \u001b[38;5;39mv11\u001b[0m\n",
            "[Vec. CC] Style Sheet Loaded...\n",
            "2025-08-06 15:30:02,899 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet UI callback registered.\n",
            "Model selected: {'checkpoint_info': {'filename': '/content/stable-diffusion-webui-forge/models/Stable-diffusion/waiNSFWIllustrious_v140.safetensors', 'hash': '366c99fd'}, 'additional_modules': ['/content/stable-diffusion-webui-forge/models/VAE/sdxl.vae.safetensors'], 'unet_storage_dtype': None}\n",
            "Using online LoRAs in FP16: False\n",
            "Running on local URL:  http://0.0.0.0:7860\n",
            "Running on public URL: https://7c775063abe9ad9924.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "\u001b[92mIIB Database file has been successfully backed up to the backup folder.\u001b[0m\n",
            "GenParamsGetter detected!\n",
            "GenParamsGetter detected!\n",
            "Startup time: 26.5s (prepare environment: 4.2s, launcher: 0.5s, import torch: 11.5s, other imports: 0.3s, load scripts: 3.2s, create ui: 3.5s, gradio launch: 3.0s, app_started_callback: 0.4s).\n",
            "Environment vars changed: {'stream': False, 'inference_memory': 1024.0, 'pin_shared_memory': False}\n",
            "[GPU Setting] You will use 97.47% GPU memory (39482.00 MB) to load weights, and use 2.53% GPU memory (1024.00 MB) to do matrix computation.\n",
            "Environment vars changed: {'stream': False, 'inference_memory': 26428.0, 'pin_shared_memory': False}\n",
            "[GPU Setting] You will use 34.76% GPU memory (14078.00 MB) to load weights, and use 65.24% GPU memory (26428.00 MB) to do matrix computation.\n",
            "Environment vars changed: {'stream': False, 'inference_memory': 1024.0, 'pin_shared_memory': False}\n",
            "[GPU Setting] You will use 97.47% GPU memory (39482.00 MB) to load weights, and use 2.53% GPU memory (1024.00 MB) to do matrix computation.\n",
            "Loading Model: {'checkpoint_info': {'filename': '/content/stable-diffusion-webui-forge/models/Stable-diffusion/waiNSFWIllustrious_v140.safetensors', 'hash': '366c99fd'}, 'additional_modules': ['/content/stable-diffusion-webui-forge/models/VAE/sdxl.vae.safetensors'], 'unet_storage_dtype': None}\n",
            "[Unload] Trying to free all memory for cuda:0 with 0 models keep loaded ... Done.\n",
            "StateDict Keys: {'unet': 1680, 'vae': 250, 'text_encoder': 197, 'text_encoder_2': 518, 'ignore': 0}\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "IntegratedAutoencoderKL Unexpected: ['model_ema.decay', 'model_ema.num_updates']\n",
            "K-Model Created: {'storage_dtype': torch.float16, 'computation_dtype': torch.float16}\n",
            "Model loaded in 1.2s (unload existing model: 0.5s, forge model load: 0.7s).\n",
            "activating extra network lora with arguments [<modules.extra_networks.ExtraNetworkParams object at 0x79a7f47331d0>, <modules.extra_networks.ExtraNetworkParams object at 0x79a7f49c8e10>, <modules.extra_networks.ExtraNetworkParams object at 0x79a7edf4bd10>]: AttributeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui-forge/extensions-builtin/sd_forge_lora/networks.py\", line 94, in load_networks\n",
            "    net = load_network(name, network_on_disk)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/stable-diffusion-webui-forge/extensions-builtin/sd_forge_lora/networks.py\", line 63, in load_network\n",
            "    net.mtime = os.path.getmtime(network_on_disk.filename)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'filename'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui-forge/modules/extra_networks.py\", line 135, in activate\n",
            "    extra_network.activate(p, extra_network_args)\n",
            "  File \"/content/stable-diffusion-webui-forge/extensions-builtin/sd_forge_lora/extra_networks_lora.py\", line 45, in activate\n",
            "    networks.load_networks(names, te_multipliers, unet_multipliers, dyn_dims)\n",
            "  File \"/content/stable-diffusion-webui-forge/extensions-builtin/sd_forge_lora/networks.py\", line 96, in load_networks\n",
            "    errors.display(e, f\"loading network {network_on_disk.filename}\")\n",
            "                                         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'filename'\n",
            "\n",
            "[Unload] Trying to free 3051.58 MB for cuda:0 with 0 models keep loaded ... Done.\n",
            "[Memory Management] Target: JointTextEncoder, Free GPU: 40062.77 MB, Model Require: 1559.68 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 37479.09 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 0.50 seconds\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 38207.07 MB ... Done.\n",
            "[Unload] Trying to free 7630.80 MB for cuda:0 with 0 models keep loaded ... Current free memory is 38205.57 MB ... Done.\n",
            "[Memory Management] Target: KModel, Free GPU: 38205.57 MB, Model Require: 4897.05 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 32284.52 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 1.63 seconds\n",
            " 18% 5/28 [00:00<00:04,  5.36it/s]\n",
            "[Unload] Trying to free 4410.28 MB for cuda:0 with 0 models keep loaded ... Current free memory is 33197.99 MB ... Done.\n",
            "[Memory Management] Target: IntegratedAutoencoderKL, Free GPU: 33197.99 MB, Model Require: 159.56 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 32014.43 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 0.05 seconds\n",
            "activating extra network lora with arguments [<modules.extra_networks.ExtraNetworkParams object at 0x79a7edc8f4d0>, <modules.extra_networks.ExtraNetworkParams object at 0x79a7edc8eb10>, <modules.extra_networks.ExtraNetworkParams object at 0x79a7edd7bd50>]: AttributeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui-forge/extensions-builtin/sd_forge_lora/networks.py\", line 94, in load_networks\n",
            "    net = load_network(name, network_on_disk)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/stable-diffusion-webui-forge/extensions-builtin/sd_forge_lora/networks.py\", line 63, in load_network\n",
            "    net.mtime = os.path.getmtime(network_on_disk.filename)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'filename'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui-forge/modules/extra_networks.py\", line 135, in activate\n",
            "    extra_network.activate(p, extra_network_args)\n",
            "  File \"/content/stable-diffusion-webui-forge/extensions-builtin/sd_forge_lora/extra_networks_lora.py\", line 45, in activate\n",
            "    networks.load_networks(names, te_multipliers, unet_multipliers, dyn_dims)\n",
            "  File \"/content/stable-diffusion-webui-forge/extensions-builtin/sd_forge_lora/networks.py\", line 96, in load_networks\n",
            "    errors.display(e, f\"loading network {network_on_disk.filename}\")\n",
            "                                         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'filename'\n",
            "\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 33031.52 MB ... Done.\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 33030.91 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 33029.41 MB ... Done.\n",
            "100% 28/28 [00:02<00:00,  9.74it/s]\n",
            "[Unload] Trying to free 4202.86 MB for cuda:0 with 1 models keep loaded ... Current free memory is 33026.93 MB ... Done.\n",
            "activating extra network lora with arguments [<modules.extra_networks.ExtraNetworkParams object at 0x79a7edd90b10>, <modules.extra_networks.ExtraNetworkParams object at 0x79a8013381d0>, <modules.extra_networks.ExtraNetworkParams object at 0x79a801338ed0>]: AttributeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui-forge/extensions-builtin/sd_forge_lora/networks.py\", line 94, in load_networks\n",
            "    net = load_network(name, network_on_disk)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/stable-diffusion-webui-forge/extensions-builtin/sd_forge_lora/networks.py\", line 63, in load_network\n",
            "    net.mtime = os.path.getmtime(network_on_disk.filename)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'filename'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui-forge/modules/extra_networks.py\", line 135, in activate\n",
            "    extra_network.activate(p, extra_network_args)\n",
            "  File \"/content/stable-diffusion-webui-forge/extensions-builtin/sd_forge_lora/extra_networks_lora.py\", line 45, in activate\n",
            "    networks.load_networks(names, te_multipliers, unet_multipliers, dyn_dims)\n",
            "  File \"/content/stable-diffusion-webui-forge/extensions-builtin/sd_forge_lora/networks.py\", line 96, in load_networks\n",
            "    errors.display(e, f\"loading network {network_on_disk.filename}\")\n",
            "                                         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'filename'\n",
            "\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 33027.41 MB ... Done.\n",
            "100% 28/28 [00:02<00:00,  9.66it/s]\n",
            "[Unload] Trying to free 4202.86 MB for cuda:0 with 1 models keep loaded ... Current free memory is 33024.93 MB ... Done.\n",
            "[LORA] Loaded /content/stable-diffusion-webui-forge/models/Lora/NSFWFilterXL_animagine.safetensors for KModel-UNet with 722 keys at weight 0.7 (skipped 0 keys) with on_the_fly = False\n",
            "[LORA] Loaded /content/stable-diffusion-webui-forge/models/Lora/NSFWFilterXL_animagine.safetensors for KModel-CLIP with 264 keys at weight 0.7 (skipped 0 keys) with on_the_fly = False\n",
            "[LORA] Loaded /content/stable-diffusion-webui-forge/models/Lora/Different_sex_positions_feets_on_screen-000009.safetensors for KModel-UNet with 722 keys at weight 0.8 (skipped 0 keys) with on_the_fly = False\n",
            "[LORA] Loaded /content/stable-diffusion-webui-forge/models/Lora/Different_sex_positions_feets_on_screen-000009.safetensors for KModel-CLIP with 264 keys at weight 0.8 (skipped 0 keys) with on_the_fly = False\n",
            "[LORA] Loaded /content/stable-diffusion-webui-forge/models/Lora/BDSM_0.2.safetensors for KModel-UNet with 722 keys at weight 0.65 (skipped 0 keys) with on_the_fly = False\n",
            "[LORA] Loaded /content/stable-diffusion-webui-forge/models/Lora/BDSM_0.2.safetensors for KModel-CLIP with 264 keys at weight 0.65 (skipped 0 keys) with on_the_fly = False\n",
            "[LORA] Loaded /content/stable-diffusion-webui-forge/models/Lora/add-detail-xl.safetensors for KModel-UNet with 722 keys at weight 0.5 (skipped 0 keys) with on_the_fly = False\n",
            "[LORA] Loaded /content/stable-diffusion-webui-forge/models/Lora/add-detail-xl.safetensors for KModel-CLIP with 264 keys at weight 0.5 (skipped 0 keys) with on_the_fly = False\n",
            "[Unload] Trying to free 1593.72 MB for cuda:0 with 0 models keep loaded ... Current free memory is 33025.65 MB ... Done.\n",
            "[Memory Management] Target: JointTextEncoder, Free GPU: 33025.65 MB, Model Require: 0.00 MB, Previously Loaded: 1752.98 MB, Inference Require: 1024.00 MB, Remaining: 32001.65 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 1.14 seconds\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 33026.00 MB ... Done.\n",
            "[Unload] Trying to free 2856.18 MB for cuda:0 with 0 models keep loaded ... Current free memory is 33026.41 MB ... Done.\n",
            "[Memory Management] Target: KModel, Free GPU: 33026.41 MB, Model Require: 0.00 MB, Previously Loaded: 4897.05 MB, Inference Require: 1024.00 MB, Remaining: 32002.41 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 4.00 seconds\n",
            "100% 28/28 [00:02<00:00,  9.68it/s]\n",
            "[Unload] Trying to free 4202.86 MB for cuda:0 with 1 models keep loaded ... Current free memory is 33047.99 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 33047.99 MB ... Done.\n",
            "100% 28/28 [00:02<00:00,  9.66it/s]\n",
            "[Unload] Trying to free 4202.86 MB for cuda:0 with 1 models keep loaded ... Current free memory is 33047.51 MB ... Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y Pillow\n",
        "!pip install Pillow==11.3.0 --force-reinstall"
      ],
      "metadata": {
        "id": "q9YOm-mqyAgZ",
        "outputId": "ad500971-9100-4132-c2e4-1b2fa4b13d64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Pillow 9.5.0\n",
            "Uninstalling Pillow-9.5.0:\n",
            "  Successfully uninstalled Pillow-9.5.0\n",
            "Collecting Pillow==11.3.0\n",
            "  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blendmodes 2022 requires numpy<2,>=1.22.1, but you have numpy 2.0.2 which is incompatible.\n",
            "blendmodes 2022 requires Pillow<10,>=9.0.0, but you have pillow 11.3.0 which is incompatible.\n",
            "gradio 4.40.0 requires markupsafe~=2.0, but you have markupsafe 3.0.2 which is incompatible.\n",
            "gradio 4.40.0 requires pillow<11.0,>=8.0, but you have pillow 11.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-11.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch /content/stable-diffusion-webui-forge/requirements_versions.txt\n",
        "\n",
        "%%writefile /content/stable-diffusion-webui-forge/requirements_versions.txt\n",
        "GitPython==3.1.32\n",
        "Pillow==9.5.0\n",
        "accelerate==0.31.0\n",
        "blendmodes==2022\n",
        "clean-fid==0.1.35\n",
        "diskcache==5.6.3\n",
        "einops\n",
        "facexlib==0.3.0\n",
        "fastapi==0.104.1\n",
        "gradio==4.40.0\n",
        "httpcore==0.15\n",
        "inflection==0.5.1\n",
        "jsonmerge==1.8.0\n",
        "kornia==0.6.7\n",
        "lark==1.1.2\n",
        "numpy\n",
        "omegaconf==2.2.3\n",
        "open-clip-torch==2.20.0\n",
        "piexif==1.1.3\n",
        "protobuf\n",
        "psutil==5.9.5\n",
        "pytorch_lightning==1.9.4\n",
        "resize-right==0.0.2\n",
        "safetensors\n",
        "scikit-image\n",
        "spandrel==0.3.4\n",
        "spandrel-extra-arches==0.1.1\n",
        "tomesd==0.1.3\n",
        "torch\n",
        "torchdiffeq==0.2.3\n",
        "torchsde==0.2.6\n",
        "transformers==4.46.1\n",
        "httpx==0.24.1\n",
        "pillow-avif-plugin==1.4.3\n",
        "diffusers==0.31.0\n",
        "gradio_rangeslider==0.0.6\n",
        "gradio_imageslider==0.0.20\n",
        "loadimg==0.1.2\n",
        "tqdm==4.66.1\n",
        "peft==0.13.2\n",
        "pydantic==2.8.2\n",
        "huggingface-hub==0.26.2"
      ],
      "metadata": {
        "id": "YexICOXlsoLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **下载生成图片(Pydrive2)**\n",
        "# @markdown Download file manually from files tab or save to Google Drive\n",
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from colablib.colored_print import cprint\n",
        "\n",
        "# --- PyDrive2 和新版认证库的导入 ---\n",
        "# 注意：首先需要确保 pydrive2 已安装。如果未安装，请先运行 !pip install PyDrive2\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "\n",
        "# ---------------------------------------------\n",
        "\n",
        "os.chdir(output_dir)\n",
        "\n",
        "use_drive = False  # @param {type:\"boolean\"}\n",
        "folder_name = \"cagliostro-forge-colab\"  # @param {type: \"string\"}\n",
        "filename = \"waifu.zip\"  # @param {type: \"string\"}\n",
        "save_as = filename\n",
        "\n",
        "def get_unique_filename(base_filename):\n",
        "    path = Path(base_filename)\n",
        "    if not path.exists():\n",
        "        return path\n",
        "    i = 1\n",
        "    while True:\n",
        "        new_path = path.with_name(f\"{path.stem}({i}){path.suffix}\")\n",
        "        if not new_path.exists():\n",
        "            return new_path\n",
        "        i += 1\n",
        "\n",
        "# filename = get_unique_filename(filename) # 我们将这个逻辑移到上传函数内部，以确保在Drive上也是唯一的\n",
        "\n",
        "def zip_directory(directory, zipname):\n",
        "    cprint(f\"Zipping contents of {directory} into {zipname}...\", color=\"blue\")\n",
        "    with zipfile.ZipFile(zipname, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for file_path in directory.rglob('*'):\n",
        "            if file_path.is_file():\n",
        "                # 使用相对路径，避免在zip文件中创建完整的/content/drive/...结构\n",
        "                relative_path = file_path.relative_to(directory)\n",
        "                zipf.write(file_path, relative_path)\n",
        "    cprint(\"Zipping complete.\", color=\"green\")\n",
        "\n",
        "# 将输出打包到 /content 目录，这是一个中立的临时位置\n",
        "zip_path = Path('/content/outputs.zip')\n",
        "zip_directory(output_dir, zip_path)\n",
        "\n",
        "if use_drive:\n",
        "    # --- PyDrive2 的认证流程 ---\n",
        "    # 这一部分是核心改动，变得更加简洁和自动化\n",
        "    gauth = GoogleAuth()\n",
        "    # .Authorize() 会自动检测到Colab环境，并触发弹窗认证流程\n",
        "    gauth.Authorize()\n",
        "    drive_service = GoogleDrive(gauth)\n",
        "    # -----------------------------\n",
        "    cprint(\"Google Drive authentication successful.\", color=\"green\")\n",
        "\n",
        "\n",
        "    def create_folder(folder_name):\n",
        "        # 查找文件夹的逻辑与pydrive完全相同\n",
        "        query = f\"title='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "        file_list = drive_service.ListFile({\"q\": query}).GetList()\n",
        "        if file_list:\n",
        "            cprint(f\"Found existing folder '{folder_name}' in Google Drive.\", color=\"green\")\n",
        "            return file_list[0][\"id\"]\n",
        "        else:\n",
        "            cprint(f\"Creating new folder '{folder_name}' in Google Drive...\", color=\"blue\")\n",
        "            folder = drive_service.CreateFile({\n",
        "                \"title\": folder_name,\n",
        "                \"mimeType\": \"application/vnd.google-apps.folder\"\n",
        "            })\n",
        "            folder.Upload()\n",
        "            return folder[\"id\"]\n",
        "\n",
        "    def upload_file(file_path_to_upload, folder_id, save_as_filename):\n",
        "        # 为了避免文件名冲突，我们在这里检查并生成唯一的文件名\n",
        "        query = f\"'{folder_id}' in parents and trashed=false\"\n",
        "        file_list = drive_service.ListFile({'q': query}).GetList()\n",
        "        existing_filenames = [f['title'] for f in file_list]\n",
        "\n",
        "        unique_path = Path(save_as_filename)\n",
        "        i = 1\n",
        "        while unique_path.name in existing_filenames:\n",
        "             unique_path = unique_path.with_name(f\"{unique_path.stem}({i}){unique_path.suffix}\")\n",
        "             i += 1\n",
        "\n",
        "        cprint(f\"Uploading '{file_path_to_upload.name}' as '{unique_path.name}' to Google Drive...\", color=\"blue\")\n",
        "        file = drive_service.CreateFile({\"title\": unique_path.name, \"parents\": [{\"id\": folder_id}]})\n",
        "        file.SetContentFile(str(file_path_to_upload))\n",
        "        file.Upload()\n",
        "        # 共享文件的逻辑也完全相同\n",
        "        file.InsertPermission({\"type\": \"anyone\", \"value\": \"anyone\", \"role\": \"reader\"})\n",
        "        return file\n",
        "\n",
        "    try:\n",
        "        folder_id = create_folder(folder_name)\n",
        "        uploaded_file = upload_file(zip_path, folder_id, save_as)\n",
        "        sharing_link = uploaded_file.get('alternateLink') or f\"https://drive.google.com/file/d/{uploaded_file['id']}/view?usp=sharing\"\n",
        "        cprint(f\"Upload complete!\", color=\"green\")\n",
        "        cprint(f\"Your sharing link: {sharing_link}\", color=\"green\")\n",
        "    except Exception as e:\n",
        "        cprint(f\"An error occurred during Google Drive upload: {e}\", color=\"red\")\n",
        "\n",
        "else:\n",
        "    cprint(f\"Files zipped locally to '{zip_path}'. Download it manually from the files tab on the left.\", color=\"yellow\")"
      ],
      "metadata": {
        "id": "UyTKsCa1qUL4",
        "cellView": "form",
        "outputId": "f8d7259b-7d36-4aaf-ab66-5860ebce20b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<p style=\"color: red;\">\n",
              "pydrive is\n",
              "<a href=\"https://github.com/googlearchive/PyDrive\" target=\"_blank\">deprecated</a>\n",
              "and no longer maintained. Colab will no longer preinstall\n",
              "pydrive on 2025-07-31.\n",
              "<a href=\"https://pypi.org/project/PyDrive2\" target=\"_blank\">pydrive2</a>\n",
              "is a maintained fork of pydrive and we recommend you migrate\n",
              "your code to use pydrive2 to ensure your notebook will continue\n",
              "to function.</p>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[0;33mFiles zipped locally. Download manually from the files tab.\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}